--- 
title: "Data processing"
author: "Eric Braian Arias, Galileu Kim, Shelmith Kariuki, Abigail Paterson, Kannan Venkataramanan\n Former Members: Luiza Andrade, Serena Cocciolo, Gabriel Vaz de Melo"
site: "bookdown::bookdown_site"
output: 
  bookdown::gitbook
config:
    toc:
      collapse: subsection
    download: ["pdf"] 
documentclass: book
link-citations: yes
---

# Overview

The objective of this document is to provide you with an overview of the data infrastructure for CLIAR, describing entities, their relationships, as well as a description on the data pipeline, including (1) data extraction, (2) data quality controls, (3) data transformation and (4) data loading. As such, the document provides an overview of the data ETL process for CLIAR. We also present an overview of how data from CLIAR is used in the CLIAR Dashboard, providing an end-to-end documentation of how data is applied for analytics.

## Data Model:

This section provides you with an overview of the data model, in particular an Entity Relationship Diagram (ERD) of all entities contained in CLIAR. Note that this diagram describes the finalized data infrastructure, once all the data has been ingested, quality controlled and ingested. Given that the current data model is still evolving, we first provide a Conceptual Model of the CLIAR data infrastructure which will evolve in granularity as the requirements for CLIAR mature.

![Figure 1. Conceptual Model for CLIAR](./_book/assets/cliar_data_model.png)

This Conceptual Model for CLIAR provides us with a mapping of both the entities contained in CLIAR’s data infrastructure, as well as the structure of their relationship. Note that the Indicator entity is at the center of our model. The unit of analysis for the Indicator entity is country-year. The value of the institutional indicator varies across countries and years, and belong to a particular institutional family (e.g., Public HRM). Additionally, to apply the Closeness-to-Frontier (CTF) methodology, we require a set of country comparators, alongside the time window, to calculate the CTF score.

As the requirements for institutional analysis in CLIAR evolve, additional entities will be added to this data model. It is important to both explicitly define these entities, as well as fully mapping their relationship to pre-existing entities. This will ensure that there is full transparency in modifications to the data model. This updating will also help identify data dependencies and potential adaptations needed to ensure the model is robust.

## Data Pipeline:

This section describes the different stages of data processing in CLIAR. We describe these different stages using the convention nomenclature Extraction-Transformation-Loading (ETL). We focus on these three stages:

1.	Data Extraction: this section describes the different data sources extracted by the CLIAR data pipeline and how they are accessed. Currently, the data is being imported from two sources:
    a.	EFI 360 API: GovData360 is an initiative of the World Bank’s Governance Global Practice (GGP). It contains more than 4,700 governance-related indicators on state capacity, efficiency, openness, inclusiveness, accountability, integrity, and trust in government. The site gathers information from 35 data sources, including other World Bank sources. Gov360 is a powerful R Package that facilitates the retrieval and analysis of data related to various indicators. 
    b. Manual extraction: the team has manually collected from a variety of sources. These include: (1) ASPIRE, (2) Fraser, (3) Heritage, (4) OECD Employment Protection Laws, (5) OECD Product Market Regulations, (6) RISE, (7) Romelli (2022), (8) SPI), (9) V-DEM, (10) WDI.

2.	Data Quality Controls: this section describes the different protocols used to assess the quality of the data once it is ingested. In particular, we highlight (1) the quantitative review of data imports, as well as (2) inclusion criteria for CLIAR:
    a.	Continuity: The indicator must be updated at least once in the past five years.
    b.	Country Coverage: The indicator must cover 100 countries at least once over the past 5 years. Exceptions: An exception to the rule is if the indicator covers at least 50 countries in the past 5 years and includes at least one country for all regions. (Additional exceptions are allowed and considered on a case-by-case basis.)
    c.	Year Coverage: We include only variables that have at least 2 years of data (not per country but overall). Additionally, for each year to count, coverage must be of at least 10 countries.


3.	Data Transformation: this section describes how data is transformed once it has been both ingested and vetted for inclusion within CLIAR. This includes transformation of indicators such as normalization, as well as the application of the Closeness-to-Frontier methodology.
    a.	For the governence data pertaining to Oil and Gas, we combine them and take the average of the indicators
    b.	GCI indicators are supposed to take values from 1 to 7. However, each indicator has one country with a score above 7 and replace any values above 7 with NA.
    c.	For computation of CTF, we filter data post 2013 and we rescale indicators so a higher number is always a better performance.
    d.	Later, we calculate the country-level average for each indicator, identify worst and best performance for each indicator and finally compute closeness to frontier at indicator level by using the min –max scaling.

4.	Data Loading: this section describes how data is exported for use by the CLIAR dashboard. Note that individual TTLs may request data to be exported to them for customized analysis. As such, this section should also accommodate these use-cases.
    a.	We have two stream of codes. One for data preparation and other for the application. Once the data preparation and processing has been completed, the processed data is copied to the data folder inside the application (app) folder. This powers the functioning of the application locally. 
    b.	Once we host the application on Posit, the app folder (which includes data folder) is completely copied to the R server from where the application runs.
    c.	Note: The loading of the data is being handled in the backend by Posit Connect. This means that all of the data contained in the GitHub repository is being converted into a back-end sqlite file, which is then accessed by the Shiny App. There is no circumventing it, but what the team should aim for is to directly load a sqlite file into the RShiny repository, so that the database itself is loaded into PositConnect. Additionally, the sqlite file should be stored in a secure folder in the World Bank’s OneDrive, instead of living locally in each one of the team member’s computers.

<!--chapter:end:index.Rmd-->

```{r setup, include = FALSE}
library(tidyverse)
library(readxl)
library(here)
library(labelled)
library(haven)
library(data360r)
library(skimr)
library(knitr)
library(assertthat)
library(tibble)
library(sf)
library(janitor)
library(stringr)
library(scales)
library(naniar)
library(countrycode)
library(purrr)
library(testthat)
```

<!--chapter:end:00-setup.Rmd-->

# Process selected indicators

- Input: `data/db_variables.xlsx`
- Outputs: 
  - `data/final/db_variables.xlsx`
  - `data/final/definitions.rds`

## Load list of selected indicators

This list is filled by hand in Excel.

```{r}
db_variables <-
  read_excel(
    here(
      "data",
      "input",
      "cliar",
      "db_variables.xlsx"
    )
  ) |> 
  clean_names() |> 
  mutate(
    variable = make_clean_names(variable)
  )
```



## Save list of selected indicators in R format

```{r}
write_rds(
  db_variables,
  here(
    "data",
    "output",
    "db_variables.rds"
  )
)
```

## Save variable definitions by family

```{r}
description <- 
  function(x) {
    assign(
      x,
      db_variables %>%
        filter(family_name == x) %>%
        select(
          Indicator = var_name,
          Description = description,
          Source = source
        )
    )
  }

description <-
  lapply(
    unique(db_variables$family_name),
    description
  )

names(description) <- 
  unique(db_variables$family_name)

write_rds(
  description,
  here(
    "data",
    "output",
    "definitions.rds"
  )
)
```

<!--chapter:end:01-select-indicators.Rmd-->

# Process data

- Input: `data/input/**/*.csv`
- Output: `data/output/cliar_compiled_indicators.rds`

This script generates the consolidated indicators for the CLIAR dashboard. It imports, processes and consolidates a diverse range of datasets, including from EFI360 and others. An exhaustive list of datasets is provided below:

```{r set-up, include = FALSE}
# define list of variables
source(
  here("vars-control.R")
)

# aux. funs
source(
  here("funs.R")
)

ref_year <- 2023
```

## 1. Import data

The data was imported from (a) the EFI360 shared data and (b) manual imports.

```{r read_in}
efi <- read_dta(
  here("data", "input", "efi", "EFI360_CLIAR_1990-2022.dta")
)

romelli <- read_dta(
  here("data", "input", "romelli", "CBIData_Romelli2022.dta")
) |>
  clean_names()

debt_transparency <- read_dta(
  here("data", "input", "debt_transparency", "debt_transparency_2021-2022.dta")
)

fraser <- read_csv(
  here("data", "input", "fraser", "fraser.csv")
) |>
  clean_names()

gfdb <- read_dta(
  here("data", "input", "gfdb", "GFDB_19902021.dta")
)

oecd_epl_regular <- read_csv(
  here("data", "input", "oecd", "epl_regular.csv")
)

oecd_epl_temporary <- read_csv(
  here("data", "input", "oecd", "epl_temporary.csv")
)

oecd_pmr <- read_dta(
  here("data", "input", "pmr", "PMR_2018.dta")
)

spi <- read_csv(
  here("data", "input", "spi", "spi_index.csv")
) |> 
  clean_names()

aspire <- read_dta(
  here("data", "input", "aspire", "ASPIRE performance indicators.dta")
)

rise <- read_dta(
  here("data", "input", "rise", "RISE_20102021.dta")
)

wdi <- read_dta(
  here("data", "input", "wdi", "WDI_19902022_CLIAR.dta")
)

vdem <- read_dta(
  here("data", "input", "vdem", "VDEM_1990_2022.dta")
)

heritage <- read_dta(
  here("data", "input", "heritage", "heritage20122022.dta")
)

open_budget <- list.files(
    here("data", "input", "ibp"),
    full.names = TRUE
  ) |> 
    map_dfr(
      read_csv,
      col_select = c(ISO, year, obi)
    )

wb_country_list <- read_xlsx(
  here(
   "data",
    "input",
    "wb",
    "CLASS.xlsx"
    ),
    sheet = "Groups"
  ) %>%
  transmute(
    country_code = CountryCode,
    country_name = CountryName,
    group = GroupName,
    group_code = GroupCode
  )

wbl <- read_dta(
  here("data", "input", "wbl", "WBL_19902022_CLIAR.dta")
)

# note that North America is not included in this list
wb_regions <- c(
  "Africa Eastern and Southern",
  "Africa Western and Central",
  "East Asia & Pacific",
  "Europe & Central Asia",
  "Latin America & Caribbean",
  "Middle East & North Africa",
  "South Asia"
)

country_region_list <- wb_country_list |> 
  # this filter excludes Canada, Bermuda and USA
  filter(group %in% wb_regions) |> 
  select(country_code, region = group)
```

## 2. Process data
```{r clean_data}
# in this section, we take the EFI files, plus the manual import data,
# to process them.
# 1. efi
efi_clean <- efi |> 
  clean_names() |> 
  # fix enterprise surveys variable name
  rename_with(
    \(x) str_replace(x, "wb_survey", "wb_es_ic_frm"),
    .cols = starts_with("wb_survey")
  ) |> 
  # create PFM MIS indicator by summing over the following and rescaling:
  # GTMI_I-13       Is there a Debt Management System (DMS) in place? (foreign and domestic debt)
  # GTMI_I-14       Is there a Public Investment Management System (PIMS) in place?
  # GTMI_I-7         Is there a Tax Management Information System in place?
  # GTMI_I-6         Is there a TSA supported by FMIS to automate payments and bank reconciliation?
  # GTMI_I-5         Is there an operational FMIS in place to support core PFM functions?
  rowwise() |> 
  mutate(
    wb_gtmi_pfm_mis = sum(
      wb_gtmi_i_13,
      wb_gtmi_i_14,
      wb_gtmi_i_7,
      wb_gtmi_i_6,
      wb_gtmi_i_5
    )
  ) |> 
  ungroup() |> 
  mutate(
    wb_gtmi_pfm_mis = scale_values(wb_gtmi_pfm_mis)
  ) |> 
  # edit WJP indicators to: (1) use 2018 data for 2017 in WJP and drop data if year < 2015
  arrange(
    iso3, year
  ) |> 
  mutate(
    across(
      starts_with("wjp_rol"),
      ~ case_when(
        year == 2017 ~ lead(.), # use 2018 data for 2017
        year < 2015 ~ NA, # drop data if year < 2015
        T ~ .
      )
    )
  ) |> 
  select(
    -index,
    -country_name,
    country_code = iso3,
    year,
    everything()
  )

# 2. fraser - market regulations
fraser_clean <- fraser |>
  transmute(
    country_code = iso_code_3,
    year = as.numeric(year),
    x4diii_freedom_of_foreigners_to_visit,
    x4dii_capital_controls,
    x5a_credit_market_regulations,
    x3d_freedom_to_own_foreign_currency_bank_accounts,
    x2b_impartial_courts,
    x2e_integrity_of_the_legal_system,
    x2a_judicial_independence,
    x2f_legal_enforcement_of_contracts
  ) |>
  rename_with(
    # replace prefixes with efi conventions
    ~ str_replace(., "^x[:alnum:]+_", "fraser_efw_")
  )

# 3. romelli - central bank independence
romelli_clean <- romelli |>
  transmute(
    country_code = wb_a3,
    year = as.numeric(year),
    romelli_cbi_central_bank_independence = lvau
  )

# 4. oecd - employment protection laws
oecd_epl_regular_clean <- oecd_epl_regular |>
  filter(
    Series == "Version 4 (2013-2019)"
  ) |>
  transmute(
    # the country code used by the OECD is equivalent to the WB
    country_code = COUNTRY,
    year = as.numeric(TIME),
    oecd_epl_regular = Value
  )

oecd_epl_temporary_clean <- oecd_epl_temporary |>
  filter(
    # Series == "Version 1 (1985-2019)"
    Series == "Version 4 (2013-2019)"
  ) |>
  transmute(
    country_code = COUNTRY,
    year = as.numeric(TIME),
    oecd_epl_temporary = Value
  )

# note that there is higher coverage for regular vs. temporary contracts
oecd_epl_clean <- oecd_epl_regular_clean |>
  full_join(
    oecd_epl_temporary_clean
  )

# 5. spi - statistical performance indicators
# SPI.DIM4.1.CEN.INDEX	SPI.DIM4.1.SVY.INDEX Dimension 5.2: Standards and Methods
# SPI.DIM5.2.INDEX
spi_clean <- spi |> 
  rowwise() |> 
  # generate an average index of the census and survey indexes
  mutate(
    spi_census_and_survey_index = mean(
      c(spi_dim4_1_cen_index, spi_dim4_1_svy_index),
      na.rm = TRUE
    )
  ) |> 
  ungroup() |> 
  transmute(
    country_code = iso3c,
    year = as.numeric(date),
    spi_census_and_survey_index,
    spi_std_and_methods = spi_dim5_2_index # standards and methods
  )

# 6. aspire data
aspire_clean <- aspire |> 
  filter(
    indicator_name %in% c(
      "Adequacy of benefits (%) -All Social Protection and Labor",
      "Coverage (%) -All Social Protection and Labor"
    )
  ) |> 
  transmute(
    # identify non-country codes (aspire includes regions, for example)
    country_code = countrycode(
      Country_Code, 
      origin = "iso3c", destination = "iso3c",
      # create exception for kosovo
      custom_match = c("XKX" = "XKX")
    ),
    year = as.numeric(Year),
    Indicator_Code,
    value = val_w
  ) |> 
  filter(
    # exclude non-country codes
    !is.na(country_code)
  ) |> 
  pivot_wider(
    id_cols = c(country_code, year),
    values_from = value,
    names_from = Indicator_Code
  ) |> 
  rename(
    wb_aspire_coverage = per_allsp.cov_pop_tot,
    wb_aspire_adequacy_benefits = per_allsp.adq_pop_tot
  )

# 7. rise data
rise_clean <- rise |> 
  clean_names()

# 8. wdi data
wdi_clean <- wdi |> 
  clean_names()

# 9. vdem
vdem_clean <- vdem |> 
  clean_names()

# 10. heritage
heritage_clean <- heritage |> 
  clean_names()

# 11. OECD Product Market Regulation
oecd_pmr_clean <- oecd_pmr |> 
  select(
    country_code,
    year,
    PMR_2018_3_3,
    PMR_2018_1_3,
    PMR_2018_6,
    PMR_2018_1_4,
    PMR_2018_1_2,
    PMR_2018_2_1,
    PMR_2018_1_1,
    PMR_2018_2_2
  ) |>
  clean_names() |> 
  rename_with(
    # replace prefixes with efi conventions
    ~ paste0("oecd_", .),
    .cols = starts_with("pmr")
  )

# 12. Open Budget Survey
open_budget_clean <- open_budget |> 
  select(
    country_code = ISO,
    year,
    ibp_obs_obi = obi
  ) |> 
  # fix cambodia ISO3
  mutate(
    country_code = if_else(
      country_code == "KMH",
      "KHM",
      country_code
    )
  )

# 13. Debt Transparency
debt_transparency_clean <- debt_transparency |> 
  clean_names() |> 
  rename_with(
    # replace prefixses with efi conventions
    ~ paste0("wb_", .),
    .cols = starts_with("debt")
  )

# 14. GFDB Bank Concentration
gfdb_clean <- gfdb |> 
  clean_names() |> 
  rename_with(
    # replace prefixses with efi conventions
    ~ paste0("wb_", .),
    .cols = starts_with("gfdb")
  )

# 15. Women, Business and the Law
wbl_clean <- wbl |> 
  clean_names() |> 
  rename_with(
    # replace prefixses with efi conventions
    ~ paste0("wb_", .),
    .cols = starts_with("wbl")
  )
```

## Consolidate data
```{r consolidate_data}
excluded_country_code <- c(
  "AIA", # anguilla
  "OECD", # OECD
  "SML", # somaliland
  "ZZB", # zanzibar,
  "KMH" # unclear, listed in Open Budget Survey
)

cliar_indicators <- list(
  efi_clean,
  fraser_clean,
  romelli_clean,
  oecd_epl_clean,
  spi_clean,
  aspire_clean,
  rise_clean,
  wdi_clean,
  vdem_clean,
  heritage_clean,
  oecd_pmr_clean,
  open_budget_clean,
  debt_transparency_clean,
  gfdb_clean,
  wbl_clean
) |> 
  map(
    # fix country codes for full join
    ~ mutate(
        .,
        country_code = case_when(
          country_code == "ZAR" ~ "COD", # democratic republic of congo
          country_code == "ROM" ~ "ROU", # romania
          T ~ country_code
        )
      ) |> 
      filter(
        !(country_code %in% excluded_country_code)
      )
  ) |> 
  reduce(
    full_join,
    by = c("country_code", "year")
  ) |> 
  filter(
    year >= 1990
  )
  
# order column names
cliar_indicators <- cliar_indicators %>%
  select(
    country_code,
    year,
    sort(colnames(.)),
    -starts_with("country_name")
  ) |> 
  arrange(
    country_code,
    year
  ) |> 
  mutate(
    index = row_number()
  )
```

## Data Quality Control: Indicator Selection

```{r indicator_selection}
# verify that the indicators are selected correctly
db_variables_indicators <- db_variables |> 
  select(
    variable
  )

# only retain indicators contained in metadata + id cols
cliar_indicators_clean <- cliar_indicators |> 
  # add country names
  left_join(
    wb_country_list |> 
      distinct(country_code, country_name),
    by = "country_code"
  ) |> 
  select(
    country_code,
    country_name,
    year,
    all_of(db_variables_indicators |> pull(variable))
  )

cliar_indicators_id <- cliar_indicators_clean |> 
  colnames() %>% 
  tibble(
    variable = .
  )

test_that(
  "All indicators contained in metadata are in the CLIAR dataset",{
    expect_equal(
      nrow(
        db_variables_indicators |> 
          anti_join(cliar_indicators_id, by = "variable") |> 
          as.data.frame()
        ),
      0
    )
  }
)
```

## Compute family averages

```{r}
# compute family averages
cliar_indicators_long <-
  cliar_indicators %>%
  pivot_longer(
    any_of(vars_all),
    names_to = "variable"
  ) %>%
  select(-contains("gdp")) %>%
  left_join(
    db_variables %>%
      select(variable, var_name, family_name, family_var),
    by = "variable"
  )

# only calculate family averages for relevant institutional clusters
cliar_family_level_long <- cliar_indicators_long |>
  filter(
    family_var %in% vars_family
  ) |>
  group_by(
    country_code, year, family_var
  ) |>
  summarise(
    value = mean(value, na.rm = TRUE),
    .groups = "drop"
  )

cliar_family_level <- cliar_family_level_long |>
  pivot_wider(
    id_cols = c(country_code, year),
    names_from = family_var,
    names_glue = "{family_var}_avg",
    values_from = value
  )

cliar_indicators_clean <- cliar_indicators |>
  left_join(
    cliar_family_level,
    by = c("country_code", "year")
  )
```

## Data Quality Control: verify country_code, country_name consistency and completeness of country-year combinations
```{r country_validation}
# there are 218 country codes listed in the WB's official website
# https://datahelpdesk.worldbank.org/knowledgebase/articles/906519-world-bank-country-and-lending-groups
# a. verify that all the country codes from the official data are included
test_that(
  "Verify that all the country codes from the official data are included",
  expect_equal(
    # number of rows is zero
    cliar_indicators |> 
      distinct(country_code) |> 
        anti_join(
          wb_country_list |> 
            distinct(country_code, country_name),
          by = c("country_code")
        ) |> nrow(),
      0
  )
)

# b. verify that cliar has distinct country-year
test_that(
  "Verify that CLIAR has distinct country years",{
    expect_equal(
      nrow(cliar_indicators),
      cliar_indicators |> 
        distinct(country_code, year) |> 
        nrow()
    )
  }
)

# c. verify that all countries have complete year coverage
test_that(
  "Verify that country codes have coverage for all years",{
    expect_equal(
      # calculate number of years covered by country
      cliar_indicators |> 
        count(country_code) |> 
        pull(n) |> 
        unique(),
      ref_year - 1990
    )
  }
)
```


## Compute coverage diagnostics
```{r coverage_diagnostics}
cliar_indicators_diagnostic <- cliar_indicators_clean |>
  select(-country_name) |> 
  compute_coverage(country_code, year, ref_year - 5) |> 
  left_join(
    db_variables |> select(variable, var_name, source, family_name),
    by = c("Indicator" = "variable")
  ) |> 
  select(
    `Indicator`,
    `Indicator Name` = var_name,
    `Institutional Family` = family_name,
    everything(),
    `Data Source` = source
  ) |> 
  arrange(
    `Institutional Family`,
    Indicator
  )
```

## 7. Save data

```{r}
write_rds(
  cliar_indicators_clean,
  here(
    "data",
    "output",
    "compiled_indicators.rds"
  )
)

cliar_indicators_diagnostic |> 
    write_csv(
      here(
        "data",
        "output",
        "diagnostics_compiled_indicators.rds"
      )
    )
```

<!--chapter:end:02-process-data.Rmd-->

# Clean list of contries

- Inputs:
  - `data/output/compiled_indicators.rds`
  - `data/input/wb/CLASS.xlsx`, obtained from https://datahelpdesk.worldbank.org/knowledgebase/articles/906519-world-bank-country-and-lending-groups on September 1, 2022
  - `data/input/wb/group_list.csv`, input by the research team to list relevant groups
      
- Outputs:
  - `data/final/wb_country_list.rds`
  - `data/final/wb_country_groups.rds`

## Inputs

```{r}
  indicators <-
    read_rds(
      here(
        "data",
        "output",
        "compiled_indicators.rds"
      )
    )

  group_list <-
    read_csv(
      here(
        "data",
        "input",
        "wb",
        "group_list.csv"
      )
    )

  country_list <-
    read_xlsx(
      here(
        "data",
        "input", 
        "wb",
        "CLASS.xlsx"
      ),
      sheet = "Groups"
    ) %>%
    transmute(
      country_code = CountryCode,
      country_name = CountryName,
      group = GroupName,
      group_code = GroupCode
    )
```

## Subset country list

The only relevant countries are those we have some data for

```{r}
country_list <-
  indicators %>%
  select(country_code) %>%
  unique %>%
  left_join(country_list)
```

## Subset groups

```{r}
country_list <-
  country_list %>%
  filter(
    group %in% group_list$group_name
  ) %>%
  unique
```

## Save datasets

Dataset with list of countries in our sample

```{r}
write_rds(
  country_list,
  here(
    "data",
    "output",
    "wb_country_list.rds"
  )
)

write_rds(
  group_list,
  here(
    "data",
    "output",
    "wb_country_groups.rds"
  )
)
```

<!--chapter:end:03-clean-countries.Rmd-->

# Calculate distance to frontier

NOTE: We have to add the dynamic benchmarking that Shel has designed for us.

- Inputs:
  - `data/output/compiled_indicators.rds`
  - `data/outut/country_list.rds`
  - `data/output/db_variables.rds`
      
- Outputs:
 - `data/output/closeness_to_frontier.rds`
 - `data/output/closeness_to_frontier_long.rds`
 - `data/output/closeness_to_frontier_dynamic.rds`
 - `data/output/closeness_to_frontier_dynamic_long.rds`

## Calculate global closeness to frontier

Closeness to frontier (CTF) is global, meaning that we identify the worst and best performance in the full sample (all countries). For each indicator $i$, we compare the last available value of indicator $i$ with the worst and best
performance for indicator $i$ among all countries and in the last $y$ years (2013 - most recent data).^[In [the doing business report](https://www.doingbusiness.org/content/dam/doingBusiness/media/Annual-Reports/English/DB17-Chapters/DB17-DTF-and-DBRankings.pdf) they consider the last 5 years, but here for some indicators we have shorter time series].


1. Keep only data from after 2013

Ideally, this will use data for the last 7 years in any given year

```{r}
cliar_indicators <-
  read_rds(
    here(
      "data",
      "output",
      "compiled_indicators.rds"
    )
  ) %>%
  # we subset our data to the post-2013 period.
  # note: for the static exercise, we further subset to time period after 2018.
  # for the dynamic exercise, we maintain our cutpoint at 2013.
  filter(
    year >= 2013
  )

country_list <- read_rds(
  here(
    "data",
    "output",
    "wb_country_list.rds"
  )
)

db_variables <- read_rds(
  here(
    "data",
    "output",
    "db_variables.rds"
  )
)
```

2. Rescale indicators so a higher number denotes stronger institutions

```{r}
cliar_indicators_rescaled <- cliar_indicators |>
  mutate(
    # V-DEM: corruption
    # PRM indicators: Countries are graded between 0 (less control/involvement) and 6 (more control/involvement).
    # Methodological note for PRM indicates that 1998 and 2013 indicators are comparable,
    # but not with 2018 due to change in methodology, so we only retain post-2018 data.
    across(
      c(
        starts_with("oecd_pmr")
      ),
      ~ ifelse(year < 2018, NA, 6 - .x)
    ),
    # Enterprise Survey: Percent Of Firms Identifying X As A Major Constraint
    across(
      c(starts_with("wb_enterprisesurveys")),
      ~ 100 - .
    ),
    # Freedom house: Countries are graded between 1 (most free) and 7 (least free)
    across(
      c(starts_with("fh_fiw")),
      ~ (8 - .x)
    )
  )
```


3. Calculate country-level average for each indicator

For the static benchmark, we only calculate averages for indicators starting in the year 2018.

```{r}
country_average <-
  cliar_indicators_rescaled %>%
  filter(year >= 2018) |>
  group_by(
    country_code
  ) %>%
  summarise(
    across(
      all_of(c(vars_static_ctf, "wdi_nygdppcapppkd")),
      ~ mean(., na.rm = TRUE)
    )
  )
```

4. Identify worst and best performance for each indicator

```{r}
# static
min_max <-
  cliar_indicators_rescaled %>%
  filter(year >= 2018) |>
  summarise(
    across(
      all_of(vars_static_ctf),
      list(
        min = ~ min(., na.rm = TRUE),
        max = ~ max(., na.rm = TRUE)
      ),
      .names = "{.col}-{.fn}"
    )
  ) %>%
  pivot_longer(
    everything(),
    names_to = c("variable", ".value"),
    names_pattern = "(.*)-(.*)"
  )

# dynamic: note that there are quite a few cases of Infinite warnings (due to missingness)
min_max_dynamic <- cliar_indicators_rescaled %>%
  filter(
    between(year, 2013, 2022)
  ) |> 
  summarise(
    across(
      all_of(vars_dynamic_ctf),
      list(
        min = ~ min(., na.rm = TRUE),
        max = ~ max(., na.rm = TRUE)
      ),
      .names = "{.col}-{.fn}"
    )
  ) %>%
  pivot_longer(
    everything(),
    names_to = c("variable", ".value"),
    names_pattern = "(.*)-(.*)"
  ) %>%
  filter(!is.infinite(min) & !is.infinite(max))
```

5. Calculate closeness to frontier at indicator level

```{r}
ctf <-
  country_average %>%
  pivot_longer(
    all_of(vars_static_ctf),
    names_to = "variable"
  ) %>%
  left_join(
    min_max,
    by = "variable"
  ) %>%
  mutate(
    ctf = (min - value) / (min - max),
    ctf = ifelse(
      ctf == 0,
      0.01,
      ctf
    )
  ) %>%
  pivot_wider(
    id_cols = c("country_code"),
    names_from = "variable",
    values_from = "ctf"
  ) %>%
  select(-starts_with("gdp")) %>%
  left_join(
    country_average %>%
      select(country_code)
  )

ctf_dynamic <-
  cliar_indicators_rescaled %>%
  pivot_longer(
    all_of(vars_dynamic_ctf),
    names_to = "variable"
  ) %>%
  left_join(
    min_max_dynamic,
    by = c("variable")
  ) %>%
  mutate(
    ctf_dyn = (min - value) / (min - max),
    ctf_dyn = ifelse(
      ctf_dyn == 0,
      0.01,
      ctf_dyn
    )
  ) %>%
  pivot_wider(
    id_cols = c("country_code", "year"),
    names_from = "variable",
    values_from = "ctf_dyn"
  ) %>%
  left_join(
    cliar_indicators_rescaled %>%
      select(country_code, year)
  )
```

## Calculate median per group

```{r}
group_ctf <-
  country_list %>%
  left_join(
    ctf,
    by = "country_code"
  ) %>%
  group_by(
    group_code, group
  ) %>%
  summarise(
    across(
      c(all_of(vars_static_ctf)),
      ~ median(., na.rm = TRUE)
    )
  ) %>%
  filter(!is.na(group)) %>%
  rename(
    country_name = group,
    country_code = group_code
  )

# static
ctf <- tibble::add_column(ctf, country_group = 0, .after = "country_code")
group_ctf <- tibble::add_column(group_ctf, country_group = 1, .after = "country_code")

# dynamic
group_ctf_dynamic <- country_list %>%
  left_join(
    ctf_dynamic,
    by = "country_code",
  ) %>%
  group_by(
    group_code, group, year
  ) %>%
  summarise(
    across(
      c(all_of(vars_dynamic_ctf)),
      ~ median(., na.rm = TRUE)
    )
  ) %>%
  filter(!is.na(group)) %>%
  rename(
    country_name = group,
    country_code = group_code
  )

ctf_dynamic <- add_column(ctf_dynamic, country_group = 0, .after = "country_code")
group_ctf_dynamic <- add_column(group_ctf_dynamic, country_group = 1, .after = "country_code")
```

## Clean CTF data and incorporate logged GDP per capita

```{r}
# static
ctf <-
  ctf %>%
  # add country codes and names
  left_join(
    country_list |> distinct(country_code, country_name),
    by = c("country_code")
  ) |>
  # add gdp per capita (PPP) data
  # use average value (as in legacy ctf)
  left_join(
    country_average |> select(country_code, wdi_nygdppcapppkd),
    by = c("country_code")
  ) |>
  # rename and transform gdp per capita to log
  mutate(
    log_gdp = log(wdi_nygdppcapppkd)
  ) |>
  bind_rows(group_ctf) %>%
  ungroup() %>%
  arrange(country_name) |>
  select(
    country_code,
    country_name,
    everything()
  )

# dynamic
ctf_dynamic <-
  ctf_dynamic %>%
  # add country codes and names
  left_join(
    country_list |> distinct(country_code, country_name),
    by = c("country_code")
  ) |>
  # add gdp per capita (PPP) data
  left_join(
    cliar_indicators |> select(country_code, year, wdi_nygdppcapppkd),
    by = c("country_code", "year")
  ) |>
  # rename and transform gdp per capita to log
  mutate(
    log_gdp = log(wdi_nygdppcapppkd)
  ) |>
  bind_rows(group_ctf_dynamic) %>%
  ungroup() %>%
  arrange(country_name) |>
  select(
    country_code,
    country_name,
    everything()
  )
```

## Convert to long-form

```{r}
# static
ctf_long <-
  ctf %>%
  pivot_longer(
    all_of(vars_static_ctf),
    names_to = "variable"
  ) %>%
  select(-contains("gdp")) %>%
  left_join(
    db_variables %>%
      select(variable, var_name, family_name, family_var),
    by = "variable"
  ) %>%
  left_join(
    country_list %>%
      select(country_code, group),
    relationship = "many-to-many",
    by = "country_code",
  )

ctf_long_clean <-
  ctf_long %>%
  group_by(family_name, family_var, country_name, country_code, group, country_group) %>%
  summarise(value = median(value, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(
    variable = family_var,
    var_name = family_name
  ) %>%
  bind_rows(ctf_long)

# dynamic
ctf_dynamic_long <-
  ctf_dynamic %>%
  pivot_longer(
    all_of(vars_dynamic_ctf),
    names_to = "variable"
  ) %>%
  select(-contains("gdp")) %>%
  left_join(
    db_variables %>%
      select(variable, var_name, family_name, family_var)
  ) %>%
  left_join(
    country_list %>%
      select(country_code, group),
    relationship = "many-to-many",
    by = "country_code",
  )

ctf_dynamic_long_clean <-
  ctf_dynamic_long %>%
  group_by(family_name, family_var, country_name, country_code, country_group, group, year) %>%
  summarise(value = median(value, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(
    variable = family_var,
    var_name = family_name
  ) %>%
  bind_rows(ctf_dynamic_long)
```

## Calculate family level data

### Static

```{r}
# static
ctf_static_family <- ctf |> 
  compute_family_average(
    vars = vars_static_family_ctf,
    db_variables = db_variables
  )

# dynamic
ctf_dynamic_family <- ctf_dynamic |> 
  # only retain even years because data is updated every two-years
  filter(
    year %% 2 == 0
  ) |> 
  compute_family_average(
    vars = c(vars_dynamic_family_ctf, vars_dynamic_partial_ctf),
    type = "dynamic",
    db_variables = db_variables
  )

# join family averages to ctfs
ctf_clean <- ctf |> 
  left_join(
    ctf_static_family,
    by = "country_code"
  )

ctf_dynamic_clean <- ctf_dynamic |> 
  left_join(
    ctf_dynamic_family,
    by = c("country_code", "year")
  )
```

## Data Quality Control
```{r}
test_that(
  "All countries are covered",
  {
    expect_setequal(
      ctf_clean |> filter(country_group == 0) |> distinct(country_code) |> pull(),
      country_list |> distinct(country_code) |> pull()
    )
    expect_setequal(
      ctf_dynamic_clean |> filter(country_group == 0) |> distinct(country_code) |> pull(),
      country_list |> distinct(country_code) |> pull()
    )
  }
)

test_that(
  "All indicators are covered",
  {
    ## Shel added _avg to the pattern to take care of the new family level indicators (that all have an _avg suffix)
    expect_setequal(
      ctf_clean |> colnames() |> str_subset("year|country|gdp|_avg$", negate = TRUE),
      vars_static_ctf
    )
    expect_setequal(
      ctf_dynamic_clean |> colnames() |> str_subset("year|country|gdp|_avg$", negate = TRUE),
      vars_dynamic_ctf
    )
  }
)
```

## Update db_variables to contain the family averages

```{r}
db_variables <- db_variables %>% 
  mutate(
    across(where(is.character), str_squish)
  ) |> 
  rename(
    rank_id = indicator_order
  ) |> 
  mutate(
    rank_id = rank_id + 1
  )

# add family level vars
family_level_vars <- db_variables %>% 
  distinct(family_var, family_name) %>% 
  rowwise() %>% 
  mutate(
    variable = paste0(family_var, "_avg"),
    var_name = paste0(family_name, " Average"),
    var_level = "indicator",
    benchmarked_ctf = "Yes",
    rank_id = 1
  )

db_variables <- db_variables %>% 
  bind_rows(family_level_vars) %>%
  arrange(family_var, rank_id)
```

## Write-out data

```{r}
write_rds(
  ctf_clean,
  here(
    "data",
    "output",
    "closeness_to_frontier.rds"
  )
)

write_rds(
  ctf_long_clean,
  here(
    "data",
    "output",
    "closeness_to_frontier_long.rds"
  )
)

write_rds(
  ctf_dynamic_clean,
  here(
    "data",
    "output",
    "closeness_to_frontier_dynamic.rds"
  )
)

write_rds(
  ctf_dynamic_long_clean,
  here(
    "data",
    "output",
    "closeness_to_frontier_dynamic_long.rds"
  )
)

write_rds(
  db_variables,
  here(
    "data",
    "output",
    "db_variables.rds"
  )
)
```


<!--chapter:end:04-ctf.Rmd-->

# Create spatial data

- Inputs:
  - `data/final/closeness_to_frontier.rds`
  - `data/final/compiled_indicators.rds`
  - `data/raw/WB_countries_Admin0_lowres.geojson`, obtained from https://datacatalog.worldbank.org/int/search/dataset/0038272 on September 1, 2022
  - `data/raw/WB_disputed_areas_Admin0_10m_lowres.geojson`, obtained from https://datacatalog.worldbank.org/int/search/dataset/0038272 on September 1, 2022
  
- Output:
  - `data/final/indicators_map.rds`

## Input data 

```{r}
ctf <-
  read_rds(
    here(
      "data",
      "output",
      "closeness_to_frontier.rds"
    )
  )
avg_columns = names(ctf)[grep("_avg", names(ctf))]
raw_indicators <-
  read_rds(
    here(
      "data",
      "output",
      "compiled_indicators.rds"
    )
  )

db_variables <-
  read_rds(
    here(
      "data",
      "output",
      "db_variables.rds"
    )
  )
```

## Official WB maps 

```{r}
world_map <-
  read_sf(
    here(
      "data",
      "input",
      "wb",
      "WB_countries_Admin0_lowres.geojson"
    )
  )

disputed_areas <-
  read_sf(
    here(
      "data",
      "input",
      "wb",
      "WB_disputed_areas_Admin0_10m_lowres.geojson"
    )
  )
```

# Clean maps 

In this section, we combine the world map data with disputed areas, in order to address potential boundary conflicts. We also simplify the world map through the `st_simplify` command in order to improve loading performance on our Shiny App.

```{r}
disputed_areas <-
  disputed_areas %>%
  transmute(country_code = str_trim(WB_A3)) %>%
  filter(
    !is.na(country_code),
    country_code != ""
  )

world_map <-
  world_map %>%
  select(country_code = WB_A3) 

world_map <-
  world_map %>%
  bind_rows(
    disputed_areas
  )

# simplify map to improve loading performance
simple_world_map <-
  world_map %>%
  # fix wrapping of dateline to avoid spurious ribbon
  # source: https://github.com/r-spatial/sf/issues/1046
  st_transform(4326) %>% 
  st_wrap_dateline() |> 
  # project into robinson coordinate system
  st_transform(crs = '+proj=robin') %>%
  # simplify polygons to improve rendering
  st_simplify(
    dTolerance = 0.05
  ) 
```


# Combine maps and data

## Closeness to frontier

```{r}
ctf <-
  ctf %>%
  pivot_longer(
    cols = all_of(c(vars_static_ctf, avg_columns)),
    values_to = "ctf"
  ) %>%
  mutate(
    bin = case_when(
      ctf < .2 ~ "0.0 - 0.2",
      ctf < .4 ~ "0.2 - 0.4",
      ctf < .5 ~ "0.4 - 0.6",
      ctf < .8 ~ "0.6 - 0.8",
      ctf <= 1 ~ "0.8 - 1.0" 
    )
  ) %>%
  pivot_wider(
    id_cols = starts_with("country_"),
    names_from = name,
    values_from = c(bin, ctf)
  )
```


## Raw data

```{r}
raw <-
  raw_indicators %>%
  pivot_longer(
    cols = 4:ncol(.)
  ) %>%
  filter(!is.na(value)) %>%
  group_by(country_code,name) %>%
  filter(year == max(year)) %>%
  pivot_wider(
    values_from = c(value, year),
    names_from = name,
    id_cols = country_code
  )

final_world_map <-
  world_map %>%
  left_join(
    raw
  ) %>%
  left_join(
    ctf
  )
```


# Save datasets

```{r}
final_world_map %>%
  write_rds(
    here(
      "data",
      "output",
      "indicators_map.rds"
    )
  )
```

<!--chapter:end:05-map.Rmd-->

# Move final data to app folder

```{r}
file.copy(
  list.files(
    here(
      "data",
      "output"
    ),
    full.names = TRUE
  ),
  here(
    "..",
    "app",
    "data"
  ),
  recursive = TRUE,
  overwrite = TRUE
)
```

<!--chapter:end:06-copy-final-data.Rmd-->

